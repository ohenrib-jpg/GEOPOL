"""
Demographic Data Indexer pour RAG Pipeline
Indexe les donn√©es socio-d√©mographiques pour l'acc√®s par l'IA locale

Convertit les indicateurs d√©mographiques (OECD, Eurostat, World Bank, INSEE)
en documents structur√©s pour le syst√®me RAG.
"""

import os
import json
import logging
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class DemographicDocument:
    """Document d√©mographique pour le RAG"""
    country_code: str
    country_name: str
    indicator_id: str
    indicator_name: str
    value: float
    year: int
    source: str
    category: str
    unit: str = ""
    metadata: Dict = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class DemographicIndexer:
    """
    Indexe les donn√©es d√©mographiques pour le RAG Pipeline
    Convertit les donn√©es de la DB en Documents searchable
    """

    def __init__(self, db_manager, cache_dir: str = None):
        """
        Args:
            db_manager: Database manager pour acc√©der aux donn√©es
            cache_dir: R√©pertoire pour le cache des documents index√©s
        """
        self.db_manager = db_manager
        self.cache_dir = cache_dir or os.path.join(os.path.dirname(__file__), 'demographic_cache')
        os.makedirs(self.cache_dir, exist_ok=True)

        # Mapping des indicateurs pour des noms lisibles
        self.indicator_names = {
            # OECD
            'oecd_population': 'Population totale',
            'oecd_health': 'Indicateurs de sant√©',
            'oecd_education': 'Niveau d\'√©ducation',
            'oecd_labour': 'March√© du travail',
            'oecd_inequality': 'In√©galit√©s sociales',
            'oecd_wellbeing': 'Bien-√™tre social',
            'oecd_migration': 'Flux migratoires',
            'oecd_family': 'Structures familiales',

            # Eurostat
            'demo_pjan': 'Population par √¢ge et sexe',
            'demo_gind': 'Indicateurs d√©mographiques',
            'demo_r_d2jan': 'Densit√© de population',
            'demo_find': 'Taux de f√©condit√©',
            'demo_magec': '√Çge moyen de la maternit√©',

            # World Bank
            'SP.POP.TOTL': 'Population totale',
            'SP.POP.GROW': 'Croissance d√©mographique',
            'SP.DYN.LE00.IN': 'Esp√©rance de vie √† la naissance',
            'SP.DYN.TFRT.IN': 'Taux de f√©condit√©',
            'SP.URB.TOTL.IN.ZS': 'Population urbaine (%)',
            'NY.GDP.PCAP.CD': 'PIB par habitant',

            # INSEE
            'insee_population': 'Population INSEE',
            'insee_natalite': 'Taux de natalit√©',
            'insee_mortalite': 'Taux de mortalit√©',

            # Autres indicateurs courants
            'NY.GDP.MKTP.CD': 'PIB (valeur nominale, USD)',
            'NY.GDP.MKTP.KD.ZG': 'Croissance du PIB (%)',
            'SL.UEM.TOTL.ZS': 'Taux de ch√¥mage (% de la main-d\'≈ìuvre)',
            'SI.POV.GINI': 'Coefficient de Gini (in√©galit√©)',
            'SP.DYN.LE00.IN': 'Esp√©rance de vie √† la naissance (ann√©es)',
            'SP.DYN.TFRT.IN': 'Taux de f√©condit√© (naissances par femme)',
            'SP.URB.TOTL.IN.ZS': 'Population urbaine (% du total)',
            'nama_10_gdp': 'PIB et composantes (Eurostat)',
            'une_rt_a': 'Taux de ch√¥mage (Eurostat)',
            'hlth_rs_prshp': 'Personnel de sant√© (Eurostat)',
            'educ_uoe_enra': 'Inscriptions dans l\'√©ducation (Eurostat)',
            'ICP': 'Parit√© de pouvoir d\'achat',
            'EXR': 'Taux de change',
            'SE.XPD.TOTL.GD.ZS': 'D√©penses √©ducation (% PIB)',
            'SE.PRM.NENR': 'Taux de scolarisation primaire',
            'SH.MED.PHYS.ZS': 'M√©decins pour 1000 habitants',
        }

        # Mapping des cat√©gories pour le contexte
        self.category_descriptions = {
            'population': 'Statistiques de population et d√©mographie',
            'health': 'Indicateurs de sant√© publique',
            'education': 'Niveau d\'√©ducation et formation',
            'social': 'Indicateurs sociaux et bien-√™tre',
            'economic': 'Indicateurs √©conomiques li√©s √† la d√©mographie',
            'migration': 'Flux migratoires et mobilit√©',
            'fertility': 'Natalit√© et f√©condit√©',
            'mortality': 'Mortalit√© et esp√©rance de vie'
        }

        logger.info(f"[OK] DemographicIndexer initialis√© (cache: {self.cache_dir})")

    def index_all_data(self) -> Dict[str, int]:
        """
        Indexe toutes les donn√©es d√©mographiques disponibles

        Returns:
            Stats sur l'indexation (nombre de documents par source)
        """
        logger.info("[DATA] Indexation de toutes les donn√©es d√©mographiques...")

        stats = {
            'total': 0,
            'by_source': {},
            'by_category': {},
            'by_country': {}
        }

        try:
            # R√©cup√©rer toutes les donn√©es d√©mographiques
            conn = self.db_manager.get_connection()
            cursor = conn.cursor()

            # Query pour r√©cup√©rer tous les indicateurs
            cursor.execute("""
                SELECT
                    country_code,
                    country_name,
                    indicator_id,
                    value,
                    year,
                    source,
                    category,
                    unit
                FROM demographic_data
                WHERE value IS NOT NULL
                ORDER BY country_code, indicator_id, year DESC
            """)

            rows = cursor.fetchall()
            logger.info(f"üì¶ {len(rows)} enregistrements r√©cup√©r√©s de la base de donn√©es")

            # Convertir en documents
            documents = []
            for row in rows:
                doc = DemographicDocument(
                    country_code=row[0],
                    country_name=row[1] or self._get_country_name(row[0]),
                    indicator_id=row[2],
                    indicator_name=self.indicator_names.get(row[2], row[2]),
                    value=float(row[3]),
                    year=int(row[4]),
                    source=row[5],
                    category=row[6] or 'other',
                    unit=row[7] or ''
                )
                documents.append(doc)

                # Stats
                stats['by_source'][doc.source] = stats['by_source'].get(doc.source, 0) + 1
                stats['by_category'][doc.category] = stats['by_category'].get(doc.category, 0) + 1
                stats['by_country'][doc.country_code] = stats['by_country'].get(doc.country_code, 0) + 1

            stats['total'] = len(documents)

            # Sauvegarder les documents dans le cache
            self._save_to_cache(documents)

            logger.info(f"[OK] Indexation termin√©e: {stats['total']} documents")
            logger.info(f"   Par source: {stats['by_source']}")
            logger.info(f"   Par cat√©gorie: {stats['by_category']}")

            return stats

        except Exception as e:
            logger.error(f"[ERROR] Erreur indexation: {e}", exc_info=True)
            return stats

    def search_documents(self, query: str, limit: int = 20) -> List[Dict]:
        """
        Recherche dans les documents index√©s

        Args:
            query: Requ√™te de recherche (mots-cl√©s, pays, indicateurs)
            limit: Nombre maximum de r√©sultats

        Returns:
            Liste de documents format√©s pour le RAG
        """
        logger.info(f"[SEARCH] Recherche d√©mographique: '{query}'")

        # Charger les documents du cache
        documents = self._load_from_cache()

        if not documents:
            logger.warning("[WARN] Aucun document en cache, indexation n√©cessaire")
            self.index_all_data()
            documents = self._load_from_cache()

        # Filtrage par mots-cl√©s
        query_lower = query.lower()
        keywords = self._extract_keywords(query)

        matched_docs = []
        for doc in documents:
            score = 0

            # Construire le texte searchable
            searchable_text = f"{doc.country_name} {doc.country_code} {doc.indicator_name} {doc.indicator_id} {doc.category} {doc.source}".lower()

            # Simple keyword matching
            for keyword in keywords:
                if keyword in searchable_text:
                    score += 2

            # Query compl√®te dans le texte
            if query_lower in searchable_text:
                score += 3

            # Bonus pour les donn√©es r√©centes
            if doc.year >= 2020:
                score += 1

            if score > 0:
                matched_docs.append((score, doc))

        # Trier par score d√©croissant
        matched_docs.sort(key=lambda x: x[0], reverse=True)

        # Convertir en format RAG Document
        rag_documents = []
        for score, doc in matched_docs[:limit]:
            rag_doc = self._to_rag_document(doc, score)
            rag_documents.append(rag_doc)

        logger.info(f"[OK] {len(rag_documents)} documents trouv√©s")
        return rag_documents

    def get_country_summary(self, country_code: str) -> Dict:
        """
        G√©n√®re un r√©sum√© complet pour un pays

        Args:
            country_code: Code ISO du pays (FR, DE, etc.)

        Returns:
            R√©sum√© structur√© avec tous les indicateurs disponibles
        """
        logger.info(f"[DATA] R√©sum√© d√©mographique pour {country_code}")

        documents = self._load_from_cache()

        # Filtrer par pays
        country_docs = [doc for doc in documents if doc.country_code.upper() == country_code.upper()]

        if not country_docs:
            return {
                'country_code': country_code,
                'country_name': self._get_country_name(country_code),
                'error': 'Aucune donn√©e disponible pour ce pays'
            }

        # Organiser par cat√©gorie
        by_category = {}
        latest_year = 0

        for doc in country_docs:
            if doc.category not in by_category:
                by_category[doc.category] = []
            by_category[doc.category].append(doc)
            latest_year = max(latest_year, doc.year)

        # R√©cup√©rer les indicateurs les plus r√©cents par cat√©gorie
        summary = {
            'country_code': country_code,
            'country_name': country_docs[0].country_name,
            'latest_year': latest_year,
            'categories': {},
            'total_indicators': len(country_docs)
        }

        for category, docs in by_category.items():
            # Prendre l'indicateur le plus r√©cent de chaque type
            latest_by_indicator = {}
            for doc in docs:
                if doc.indicator_id not in latest_by_indicator or doc.year > latest_by_indicator[doc.indicator_id].year:
                    latest_by_indicator[doc.indicator_id] = doc

            summary['categories'][category] = {
                'description': self.category_descriptions.get(category, category),
                'indicators': [
                    {
                        'name': doc.indicator_name,
                        'value': doc.value,
                        'year': doc.year,
                        'unit': doc.unit,
                        'source': doc.source
                    }
                    for doc in latest_by_indicator.values()
                ]
            }

        return summary

    def _to_rag_document(self, demo_doc: DemographicDocument, relevance_score: float = 0.0) -> Dict:
        """
        Convertit un DemographicDocument en format RAG Document

        Args:
            demo_doc: Document d√©mographique
            relevance_score: Score de pertinence pour le tri

        Returns:
            Dict compatible avec rag_pipeline.Document
        """
        # Formater le contenu de mani√®re lisible
        content = f"""
{demo_doc.indicator_name} ({demo_doc.indicator_id})
Pays: {demo_doc.country_name} ({demo_doc.country_code})
Valeur: {demo_doc.value:,.2f} {demo_doc.unit}
Ann√©e: {demo_doc.year}
Source: {demo_doc.source.upper()}
Cat√©gorie: {self.category_descriptions.get(demo_doc.category, demo_doc.category)}
        """.strip()

        title = f"{demo_doc.country_name} - {demo_doc.indicator_name} ({demo_doc.year})"

        return {
            'content': content,
            'title': title,
            'source': f"demographic_{demo_doc.source}",
            'url': None,
            'timestamp': datetime.now().isoformat(),
            'relevance_score': relevance_score,
            'source_type': 'demographic',
            'metadata': {
                'country_code': demo_doc.country_code,
                'country_name': demo_doc.country_name,
                'indicator_id': demo_doc.indicator_id,
                'value': demo_doc.value,
                'year': demo_doc.year,
                'category': demo_doc.category,
                'source': demo_doc.source
            }
        }

    def _save_to_cache(self, documents: List[DemographicDocument]):
        """Sauvegarde les documents dans le cache"""
        cache_file = os.path.join(self.cache_dir, 'demographic_index.json')

        try:
            # Convertir en dict pour JSON
            docs_dict = []
            for doc in documents:
                docs_dict.append({
                    'country_code': doc.country_code,
                    'country_name': doc.country_name,
                    'indicator_id': doc.indicator_id,
                    'indicator_name': doc.indicator_name,
                    'value': doc.value,
                    'year': doc.year,
                    'source': doc.source,
                    'category': doc.category,
                    'unit': doc.unit,
                    'metadata': doc.metadata
                })

            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': datetime.now().isoformat(),
                    'total': len(docs_dict),
                    'documents': docs_dict
                }, f, ensure_ascii=False, indent=2)

            logger.info(f"üíæ Cache sauvegard√©: {len(docs_dict)} documents")

        except Exception as e:
            logger.error(f"[ERROR] Erreur sauvegarde cache: {e}")

    def _load_from_cache(self) -> List[DemographicDocument]:
        """Charge les documents depuis le cache"""
        cache_file = os.path.join(self.cache_dir, 'demographic_index.json')

        if not os.path.exists(cache_file):
            return []

        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            documents = []
            for doc_dict in data.get('documents', []):
                doc = DemographicDocument(
                    country_code=doc_dict['country_code'],
                    country_name=doc_dict['country_name'],
                    indicator_id=doc_dict['indicator_id'],
                    indicator_name=doc_dict['indicator_name'],
                    value=doc_dict['value'],
                    year=doc_dict['year'],
                    source=doc_dict['source'],
                    category=doc_dict['category'],
                    unit=doc_dict.get('unit', ''),
                    metadata=doc_dict.get('metadata', {})
                )
                documents.append(doc)

            logger.info(f"üì¶ Cache charg√©: {len(documents)} documents")
            return documents

        except Exception as e:
            logger.error(f"[ERROR] Erreur chargement cache: {e}")
            return []

    def _extract_keywords(self, query: str) -> List[str]:
        """Extrait les mots-cl√©s de la requ√™te"""
        import re

        query = re.sub(r'[^\w\s]', '', query.lower())
        words = query.split()

        # Stopwords fran√ßais
        stopwords = {
            'le', 'la', 'les', 'de', 'des', 'du', 'et', 'en', 'un', 'une',
            '√†', 'au', 'aux', 'dans', 'sur', 'par', 'pour', 'avec', 'sans'
        }

        keywords = [word for word in words if len(word) > 2 and word not in stopwords]
        return keywords

    def _get_country_name(self, country_code: str) -> str:
        """R√©cup√®re le nom complet d'un pays depuis son code"""
        country_names = {
            'FR': 'France',
            'DE': 'Allemagne',
            'IT': 'Italie',
            'ES': 'Espagne',
            'GB': 'Royaume-Uni',
            'US': '√âtats-Unis',
            'CN': 'Chine',
            'JP': 'Japon',
            'BE': 'Belgique',
            'NL': 'Pays-Bas',
            'SE': 'Su√®de',
            'DK': 'Danemark',
            'NO': 'Norv√®ge',
            'FI': 'Finlande',
            'PL': 'Pologne',
            'PT': 'Portugal',
            'GR': 'Gr√®ce',
            'AT': 'Autriche',
            'CH': 'Suisse',
            'IE': 'Irlande'
        }
        return country_names.get(country_code.upper(), country_code)


# Fonction factory
def create_demographic_indexer(db_manager, cache_dir: str = None):
    """Cr√©e une instance du DemographicIndexer"""
    return DemographicIndexer(db_manager=db_manager, cache_dir=cache_dir)
