# Flask/insee_scraper.py
"""
Scraper l√©ger et respectueux pour les indicateurs cl√©s INSEE
R√©cup√®re inflation, ch√¥mage et croissance depuis la page d'accueil
Usage √©ducatif - 1 requ√™te par jour maximum
"""

import logging
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import json
import re
import os

logger = logging.getLogger(__name__)


class INSEEScraper:
    """Scraper pour les indicateurs cl√©s INSEE"""
    
    INSEE_URL = "https://www.insee.fr/fr/accueil"
    CACHE_DURATION_HOURS = 24  # Cache 24h
    
    # Fallback values (derni√®res donn√©es connues)
    FALLBACK_DATA = {
        'inflation': {
            'value': 2.1,
            'period': '2024-12',
            'name': 'Inflation (glissement annuel)',
            'unit': '%'
        },
        'unemployment': {
            'value': 7.4,
            'period': '2024-Q3',
            'name': 'Taux de ch√¥mage',
            'unit': '%'
        },
        'growth': {
            'value': 0.9,
            'period': '2024-Q4',
            'name': 'Croissance du PIB',
            'unit': '% (variation trimestrielle)'
        }
    }
    
    def __init__(self, cache_file: str = 'instance/insee_cache.json'):
        self.cache_file = cache_file
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'fr-FR,fr;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        })
        logger.info("‚úÖ INSEEScraper initialis√©")
    
    def get_indicators(self) -> Dict[str, Any]:
        """
        R√©cup√®re les 3 indicateurs cl√©s INSEE
        Avec syst√®me de cache intelligent
        """
        # V√©rifier le cache d'abord
        cached_data = self._load_from_cache()
        if cached_data and self._is_cache_valid(cached_data):
            logger.info("üì¶ Utilisation donn√©es INSEE depuis cache")
            cached_data['source'] = 'Cache INSEE'
            return cached_data
        
        # Tenter de scraper les nouvelles donn√©es
        try:
            logger.info("üåê R√©cup√©ration donn√©es INSEE depuis le site...")
            fresh_data = self._scrape_insee_homepage()
            
            if fresh_data and self._validate_data(fresh_data):
                self._save_to_cache(fresh_data)
                logger.info("‚úÖ Donn√©es INSEE fra√Æches r√©cup√©r√©es")
                return fresh_data
            else:
                logger.warning("‚ö†Ô∏è Donn√©es scrap√©es invalides, utilisation fallback")
                fallback_data = self._get_fallback_data()
                fallback_data['note'] = 'Donn√©es scrap√©es invalides - utilisation fallback'
                return fallback_data
        
        except Exception as e:
            logger.error(f"‚ùå Erreur scraping INSEE: {e}")
            # Retourner le cache m√™me expir√© ou fallback
            if cached_data:
                logger.info("üì¶ Utilisation cache expir√© en secours")
                cached_data['note'] = f'Cache expir√© - erreur scraping: {str(e)[:50]}'
                return cached_data
            else:
                logger.info("üîÑ Utilisation donn√©es fallback")
                fallback_data = self._get_fallback_data()
                fallback_data['note'] = f'Erreur scraping - fallback: {str(e)[:50]}'
                return fallback_data
    
    def _scrape_insee_homepage(self) -> Optional[Dict[str, Any]]:
        """
        Scrape la page d'accueil INSEE pour extraire les indicateurs
        M√©thode respectueuse : 1 seule requ√™te, timeout court
        """
        try:
            response = self.session.get(
                self.INSEE_URL,
                timeout=20,
                allow_redirects=True,
                verify=True
            )
            
            if response.status_code != 200:
                logger.warning(f"‚ö†Ô∏è Status code INSEE: {response.status_code}")
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Nouvelle strat√©gie : recherche des cartes de chiffres cl√©s
            indicators = self._extract_from_modern_layout(soup)
            
            # Si pas assez d'indicateurs, essayer l'ancienne m√©thode
            if len(indicators) < 2:
                logger.info("Essai extraction avec m√©thode alternative")
                alternative_indicators = self._extract_alternative_method(soup)
                indicators.update(alternative_indicators)
            
            # Nettoyer et valider les indicateurs
            cleaned_indicators = {}
            for key, data in indicators.items():
                if data and isinstance(data, dict) and 'value' in data and data['value'] is not None:
                    try:
                        # Convertir la valeur en float si c'est une string
                        if isinstance(data['value'], str):
                            clean_match = re.search(r'([+-]?\d+[,\.]?\d*)', data['value'])
                            if clean_match:
                                clean_value = float(clean_match.group(1).replace(',', '.'))
                            else:
                                continue
                        else:
                            clean_value = float(data['value'])
                        
                        # Validation
                        if self._is_value_reasonable(clean_value, key):
                            data['value'] = clean_value
                            cleaned_indicators[key] = data
                        else:
                            logger.warning(f"‚ö†Ô∏è Valeur aberrante pour {key}: {clean_value}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erreur traitement valeur {key}: {e}")
                        continue
            
            if cleaned_indicators:
                return {
                    'success': True,
                    'indicators': cleaned_indicators,
                    'timestamp': datetime.now().isoformat(),
                    'source': 'INSEE scraping direct',
                    'scraped_url': self.INSEE_URL,
                    'note': 'Donn√©es extraites de la page d\'accueil INSEE'
                }
            else:
                return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur scraping: {e}")
            return None
    
    def _extract_from_modern_layout(self, soup) -> Dict[str, Dict]:
        """Extraction depuis la mise en page moderne d'INSEE"""
        indicators = {}
        
        # Recherche des sections de chiffres cl√©s
        sections = soup.find_all(['section', 'div', 'article'], 
                                class_=re.compile(r'(chiffre|figure|indicateur|key|stat|data|valeur)', re.I))
        
        for section in sections:
            text_content = section.get_text(strip=True, separator=' ')
            lower_content = text_content.lower()
            
            # V√©rifier si c'est un √©l√©ment contenant des chiffres
            if len(text_content) < 200:  # √âviter les grands textes
                # Inflation
                if any(keyword in lower_content for keyword in ['inflation', 'ipc', 'prix', 'consommation', 'hausse', 'indice']):
                    if 'inflation' not in indicators:  # Prendre la premi√®re occurrence
                        value = self._extract_numeric_value(text_content)
                        if value is not None:
                            indicators['inflation'] = {
                                'value': value,
                                'period': self._extract_period_from_text(text_content),
                                'name': 'Inflation (glissement annuel)',
                                'unit': '%',
                                'source': 'INSEE homepage',
                                'confidence': 'medium'
                            }
                
                # Ch√¥mage
                elif any(keyword in lower_content for keyword in ['ch√¥mage', 'chomage', 'emploi', 'actifs', 'taux']):
                    if 'unemployment' not in indicators:
                        value = self._extract_numeric_value(text_content)
                        if value is not None:
                            indicators['unemployment'] = {
                                'value': value,
                                'period': self._extract_period_from_text(text_content),
                                'name': 'Taux de ch√¥mage',
                                'unit': '%',
                                'source': 'INSEE homepage',
                                'confidence': 'medium'
                            }
                
                # Croissance
                elif any(keyword in lower_content for keyword in ['croissance', 'pib', 'gdp', 'produit', 'variation']):
                    if 'growth' not in indicators:
                        value = self._extract_numeric_value(text_content)
                        if value is not None:
                            indicators['growth'] = {
                                'value': value,
                                'period': self._extract_period_from_text(text_content),
                                'name': 'Croissance du PIB',
                                'unit': '% (variation trimestrielle)',
                                'source': 'INSEE homepage',
                                'confidence': 'medium'
                            }
        
        return indicators
    
    def _extract_alternative_method(self, soup) -> Dict[str, Dict]:
        """M√©thode alternative d'extraction"""
        indicators = {}
        all_text = soup.get_text()
        
        # Patterns am√©lior√©s
        patterns = {
            'inflation': [
                r'inflation.*?(\d+[,\.]\d+)\s*%',
                r'(\d+[,\.]\d+)\s*%.*?inflation',
                r'ipc.*?(\d+[,\.]\d+)\s*%'
            ],
            'unemployment': [
                r'ch√¥mage.*?(\d+[,\.]\d+)\s*%',
                r'taux.*?ch√¥mage.*?(\d+[,\.]\d+)\s*%',
                r'(\d+[,\.]\d+)\s*%.*?ch√¥mage'
            ],
            'growth': [
                r'croissance.*?pib.*?([+-]?\d+[,\.]\d+)\s*%',
                r'pib.*?([+-]?\d+[,\.]\d+)\s*%.*?croissance',
                r'variation.*?pib.*?([+-]?\d+[,\.]\d+)\s*%'
            ]
        }
        
        for indicator_type, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.findall(pattern, all_text, re.IGNORECASE | re.DOTALL)
                if matches:
                    # Prendre la derni√®re occurrence (la plus r√©cente)
                    try:
                        value_str = matches[-1]
                        value = float(value_str.replace(',', '.'))
                        if self._is_value_reasonable(value, indicator_type):
                            indicators[indicator_type] = {
                                'value': value,
                                'period': self._extract_current_period(),
                                'name': {
                                    'inflation': 'Inflation (glissement annuel)',
                                    'unemployment': 'Taux de ch√¥mage',
                                    'growth': 'Croissance du PIB'
                                }[indicator_type],
                                'unit': '%',
                                'source': 'INSEE text mining',
                                'confidence': 'low'
                            }
                            break
                    except Exception as e:
                        logger.warning(f"Erreur extraction {indicator_type}: {e}")
        
        return indicators
    
    def _extract_numeric_value(self, text: str) -> Optional[float]:
        """Extrait une valeur num√©rique d'un texte"""
        patterns = [
            r'([+-]?\d+[,\.]\d+)\s*%',
            r'([+-]?\d+[,\.]\d+)',
            r'([+-]?\d+)\s*%'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                try:
                    value_str = match.group(1).replace(',', '.')
                    return float(value_str)
                except:
                    continue
        return None
    
    def _extract_period_from_text(self, text: str) -> str:
        """Extrait la p√©riode depuis un texte"""
        # Patterns pour dates
        date_patterns = [
            r'(?:janvier|f√©vrier|mars|avril|mai|juin|juillet|ao√ªt|septembre|octobre|novembre|d√©cembre)\s+(\d{4})',
            r'T[1-4]\s+(\d{4})',
            r'(\d{4})[-‚Äì]\s*T[1-4]',
            r'(\d{4})[-‚Äì]Q[1-4]',
            r'(\d{2}/\d{4})',
            r'(\d{4}-\d{2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(0)
        
        # Par d√©faut, retourner p√©riode actuelle
        return self._extract_current_period()
    
    def _is_value_reasonable(self, value: float, indicator_type: str) -> bool:
        """V√©rifie si une valeur est raisonnable"""
        ranges = {
            'inflation': (-2, 15),      # Inflation (d√©flation √† inflation √©lev√©e)
            'unemployment': (0, 30),     # Ch√¥mage (0% √† 30%)
            'growth': (-15, 15)          # Croissance (-15% √† +15%)
        }
        
        if indicator_type in ranges:
            min_val, max_val = ranges[indicator_type]
            return min_val <= value <= max_val
        return True
    
    def _extract_current_period(self) -> str:
        """P√©riode actuelle par d√©faut"""
        now = datetime.now()
        # Retourner le trimestre pr√©c√©dent pour plus de r√©alisme
        quarter = (now.month - 1) // 3 + 1
        year = now.year
        if quarter == 0:
            quarter = 4
            year -= 1
        return f"{year}-Q{quarter}"
    
    def _validate_data(self, data: Dict) -> bool:
        """Valide les donn√©es"""
        if not data or not data.get('success'):
            return False
        
        indicators = data.get('indicators', {})
        
        # Au moins 1 indicateur valide
        if len(indicators) == 0:
            return False
        
        # V√©rifier la structure
        for key, indicator in indicators.items():
            if not isinstance(indicator, dict):
                return False
            if 'value' not in indicator or 'name' not in indicator:
                return False
        
        return True
    
    def _load_from_cache(self) -> Optional[Dict]:
        """Charge depuis le cache"""
        try:
            if not os.path.exists(self.cache_file):
                return None
            
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # V√©rifier la structure
            if isinstance(data, dict) and data.get('success'):
                return data
            elif 'indicators' in data:
                # Ancien format
                return {
                    'success': True,
                    'indicators': data.get('indicators', {}),
                    'timestamp': data.get('timestamp', datetime.now().isoformat()),
                    'source': 'Cache converti'
                }
            return None
            
        except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
            logger.warning(f"Erreur chargement cache: {e}")
            return None
    
    def _save_to_cache(self, data: Dict):
        """Sauvegarde dans le cache"""
        try:
            # Cr√©er le dossier si n√©cessaire
            cache_dir = os.path.dirname(self.cache_file)
            if cache_dir and not os.path.exists(cache_dir):
                os.makedirs(cache_dir, exist_ok=True)
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info("üíæ Cache INSEE sauvegard√©")
        except Exception as e:
            logger.error(f"Erreur sauvegarde cache: {e}")
    
    def _is_cache_valid(self, cached_data: Dict) -> bool:
        """V√©rifie la validit√© du cache"""
        try:
            timestamp = cached_data.get('timestamp')
            if not timestamp:
                return False
            
            cache_time = datetime.fromisoformat(timestamp)
            age = datetime.now() - cache_time
            return age < timedelta(hours=self.CACHE_DURATION_HOURS)
        except (KeyError, ValueError, TypeError) as e:
            logger.warning(f"Erreur validation cache: {e}")
            return False
    
    def _get_fallback_data(self) -> Dict[str, Any]:
        """Donn√©es de secours"""
        return {
            'success': True,
            'indicators': self.FALLBACK_DATA.copy(),
            'timestamp': datetime.now().isoformat(),
            'source': 'Fallback INSEE',
            'note': 'Donn√©es de r√©f√©rence - site INSEE temporairement indisponible'
        }
    
    def force_refresh(self) -> Dict[str, Any]:
        """Force un rafra√Æchissement"""
        logger.info("üîÑ Rafra√Æchissement forc√© INSEE")
        try:
            data = self._scrape_insee_homepage()
            if data and self._validate_data(data):
                self._save_to_cache(data)
                return data
        except Exception as e:
            logger.error(f"Erreur rafra√Æchissement: {e}")
        
        return self._get_fallback_data()


# Test
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    scraper = INSEEScraper()
    data = scraper.get_indicators()
    
    print("=" * 60)
    print("üìä Indicateurs INSEE")
    print("=" * 60)
    
    if data.get('success'):
        print(f"Source: {data.get('source', 'N/A')}")
        print(f"Timestamp: {data.get('timestamp', 'N/A')}")
        
        if 'note' in data:
            print(f"Note: {data['note']}")
        
        for key, indicator in data['indicators'].items():
            print(f"\n{indicator['name']}: {indicator['value']} {indicator['unit']}")
            print(f"  P√©riode: {indicator.get('period', 'N/A')}")
            print(f"  Source: {indicator.get('source', 'N/A')}")
            if 'confidence' in indicator:
                print(f"  Confiance: {indicator['confidence']}")
    else:
        print("‚ùå Erreur r√©cup√©ration donn√©es")