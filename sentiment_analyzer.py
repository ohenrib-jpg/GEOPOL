import logging
import threading
from typing import Dict, Any, List, Tuple
import numpy as np

# Importations conditionnelles
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except ImportError:
    TEXTBLOB_AVAILABLE = False
    print("‚ö†Ô∏è TextBlob non disponible")

try:
    import nltk
    from nltk.sentiment import SentimentIntensityAnalyzer
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False
    print("‚ö†Ô∏è NLTK non disponible")

try:
    from transformers import pipeline
    ROBERTA_AVAILABLE = True
    print("‚úÖ Transformers disponible - RoBERTa activable")
except ImportError:
    ROBERTA_AVAILABLE = False
    print("‚ö†Ô∏è Transformers non disponible")

logger = logging.getLogger(__name__)

class SentimentAnalyzer:
    def __init__(self):
        self.sia = None
        self.roberta_pipeline = None
        
        # üéØ LEXIQUE G√âOPOLITIQUE AM√âLIOR√â - PLUS NUANC√â
        self.geopolitical_modifiers = {
            # Termes n√©gatifs (impact r√©duit)
            'conflit': -0.25, 'guerre': -0.4, 'invasion': -0.5,
            'sanction': -0.3, 'embargo': -0.3, 'crise': -0.25,
            'tension': -0.2, 'menace': -0.25, 'attaque': -0.4,
            'bombardement': -0.5, 'victime': -0.3, 'destruction': -0.4,
            'r√©fugi√©': -0.25, 'famine': -0.4, 'r√©pression': -0.3,
            'violence': -0.3, 'instabilit√©': -0.2, 'protestation': -0.15,
            
            # Termes positifs (impact augment√©)
            'accord': 0.5, 'paix': 0.6, 'coop√©ration': 0.5,
            'diplomatie': 0.4, 'n√©gociation': 0.4, 'trait√©': 0.5,
            'alliance': 0.5, 'stabilit√©': 0.4, 'd√©veloppement': 0.4,
            'croissance': 0.4, 'investissement': 0.4, 'partenariat': 0.5,
            'progr√®s': 0.4, 'solution': 0.3, 'entente': 0.3,
            'r√©conciliation': 0.5, 'd√©tente': 0.4, 'compromis': 0.3,
            
            # Termes neutres mais souvent positifs en contexte
            '√©lection': 0.1, 'sommet': 0.2, 'r√©union': 0.15,
            'd√©claration': 0.1, 'annonce': 0.1, 'visite': 0.2,
            'dialogue': 0.3, 'consultation': 0.2, 'forum': 0.15
        }
        
        # üìä SEUILS RECALIBR√âS - PLUS PERMISSIFS POUR LE POSITIF
        self.thresholds = {
            'positive': 0.15,           # Seuil abaiss√© pour capturer plus de positif
            'neutral_positive': 0.02,   # Zone tampon √©largie
            'neutral_negative': -0.02,  # Zone neutre r√©duite
            'negative': -0.15           # Seuil relev√© pour r√©duire faux n√©gatifs
        }
        
        self._initialize_nltk()
        self._initialize_roberta()
    
    def _initialize_nltk(self):
        """Initialise NLTK en arri√®re-plan"""
        if not NLTK_AVAILABLE:
            return
            
        def download_nltk_data():
            try:
                nltk.data.find('vader_lexicon')
                logger.info("‚úÖ VADER lexicon d√©j√† disponible")
            except LookupError:
                logger.info("üì• T√©l√©chargement de VADER lexicon...")
                nltk.download('vader_lexicon', quiet=True)
                logger.info("‚úÖ VADER lexicon t√©l√©charg√©")
            
            self.sia = SentimentIntensityAnalyzer()
        
        thread = threading.Thread(target=download_nltk_data)
        thread.daemon = True
        thread.start()
    
    def _initialize_roberta(self):
        """Initialise RoBERTa en arri√®re-plan"""
        if not ROBERTA_AVAILABLE:
            print("‚ö†Ô∏è RoBERTa non disponible - mode fallback activ√©")
            return
            
        def load_roberta():
            try:
                print("ü§ñ Chargement de RoBERTa...")
                # Utilisation d'un mod√®le plus adapt√© au contexte g√©n√©ral
                self.roberta_pipeline = pipeline(
                    "sentiment-analysis",
                    model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                    truncation=True,
                    max_length=512,
                    device=-1,  # CPU
                    top_k=None  # Obtenir tous les scores
                )
                print("‚úÖ RoBERTa charg√© avec succ√®s !")
            except Exception as e:
                print(f"‚ùå Erreur chargement RoBERTa: {e}")
                # Fallback vers un mod√®le plus simple
                try:
                    self.roberta_pipeline = pipeline(
                        "sentiment-analysis",
                        model="siebert/sentiment-roberta-large-english",
                        device=-1
                    )
                    print("‚úÖ Fallback RoBERTa charg√©")
                except Exception as e2:
                    print(f"‚ùå Erreur fallback RoBERTa: {e2}")
                    self.roberta_pipeline = None
        
        load_roberta()
    
    def _apply_geopolitical_context(self, text: str, base_score: float) -> float:
        """
        üéØ Ajuste le score en fonction du contexte g√©opolitique - VERSION AM√âLIOR√âE
        """
        text_lower = text.lower()
        adjustment = 0.0
        matches = 0
        
        for term, modifier in self.geopolitical_modifiers.items():
            # Recherche plus robuste avec word boundaries
            pattern = r'\b' + re.escape(term) + r'\b'
            if re.search(pattern, text_lower):
                adjustment += modifier
                matches += 1
                logger.debug(f"üîç Terme g√©o trouv√©: '{term}' -> {modifier}")
        
        # Moyenne des ajustements trouv√©s
        if matches > 0:
            adjustment = adjustment / matches
            # M√©lange avec pond√©ration r√©duite pour le contexte (80% base, 20% contexte)
            adjusted_score = (base_score * 0.8) + (adjustment * 0.2)
            logger.debug(f"üéØ Ajustement g√©o: {base_score:.3f} ‚Üí {adjusted_score:.3f} ({matches} termes)")
            return min(max(adjusted_score, -1.0), 1.0)  # Clamping
        
        return base_score
    
    def _smooth_score(self, score: float) -> float:
        """
        üìä Lissage moins agressif pour pr√©server les nuances
        """
        # R√©duction de la compression
        smoothed = np.tanh(score * 1.2)  # Facteur augment√© pour moins compresser
        return float(smoothed)
    
    def _categorize_sentiment(self, score: float, confidence: float) -> str:
        """
        üè∑Ô∏è Cat√©gorisation plus nuanc√©e avec biais positif
        """
        # Si confiance faible, tendre vers le neutre positif
        if confidence < 0.4:
            return 'neutral_positive' if score >= -0.1 else 'neutral_negative'
        
        # Biais positif pour les scores proches de z√©ro
        if score > 0:
            # Renforcement du positif
            if score >= self.thresholds['positive']:
                return 'positive'
            elif score >= self.thresholds['neutral_positive']:
                return 'neutral_positive'
            else:
                # Scores l√©g√®rement positifs mais sous le seuil -> neutre positif
                return 'neutral_positive'
        else:
            if score <= self.thresholds['negative']:
                return 'negative'
            elif score <= self.thresholds['neutral_negative']:
                return 'neutral_negative'
            else:
                # Scores l√©g√®rement n√©gatifs mais au-dessus du seuil -> neutre n√©gatif
                return 'neutral_negative'
    
    def _extract_key_phrases(self, text: str) -> List[str]:
        """
        Extraire les phrases cl√©s pour une analyse plus pr√©cise
        """
        # D√©coupage simple en phrases
        sentences = re.split(r'[.!?]+', text)
        key_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:  # Phrases significatives
                # V√©rifier la pr√©sence de termes importants
                important_terms = ['accord', 'paix', 'coop√©ration', 'conflit', 'crise', 'n√©gociation']
                if any(term in sentence.lower() for term in important_terms):
                    key_sentences.append(sentence)
        
        return key_sentences
    
    def analyze_sentiment_with_score(self, text: str) -> Dict[str, Any]:
        """
        ‚≠ê Analyse principale avec am√©liorations significatives
        """
        if not text or len(text.strip()) < 10:
            return {
                'score': 0.05,  # L√©ger biais positif pour contenu vide
                'type': 'neutral_positive',
                'confidence': 0.0,
                'model': 'none'
            }
        
        # PRIORIT√â 1 : RoBERTa avec am√©liorations
        if self.roberta_pipeline:
            try:
                # Utiliser les phrases cl√©s si possible
                key_phrases = self._extract_key_phrases(text)
                analysis_text = ' '.join(key_phrases) if key_phrases else text[:800]
                
                result = self.roberta_pipeline(analysis_text)[0]
                
                # Traitement am√©lior√© des r√©sultats RoBERTa
                if isinstance(result, list):
                    # Mod√®le retournant multiple scores
                    scores_dict = {item['label']: item['score'] for item in result}
                    positive_score = scores_dict.get('positive', scores_dict.get('POS', 0))
                    negative_score = scores_dict.get('negative', scores_dict.get('NEG', 0))
                    neutral_score = scores_dict.get('neutral', scores_dict.get('NEU', 0))
                    
                    # Calcul du score brut normalis√©
                    raw_score = positive_score - negative_score
                    raw_confidence = max(positive_score, negative_score, neutral_score)
                    
                else:
                    # Mod√®le simple
                    label = result['label'].lower()
                    raw_confidence = result['score']
                    
                    if 'positive' in label:
                        raw_score = raw_confidence
                    elif 'negative' in label:
                        raw_score = -raw_confidence
                    else:
                        raw_score = 0.0
                
                # üéØ APPLICATION DU CONTEXTE G√âOPOLITIQUE AM√âLIOR√â
                geo_adjusted_score = self._apply_geopolitical_context(text, raw_score)
                
                # üìä LISSAGE AM√âLIOR√â
                smoothed_score = self._smooth_score(geo_adjusted_score)
                
                # üè∑Ô∏è CAT√âGORISATION INTELLIGENTE
                sentiment_type = self._categorize_sentiment(smoothed_score, raw_confidence)
                
                # Post-processing : √©viter les neutres n√©gatifs pour scores l√©g√®rement positifs
                if sentiment_type == 'neutral_negative' and smoothed_score > -0.01:
                    sentiment_type = 'neutral_positive'
                
                result = {
                    'score': smoothed_score,
                    'type': sentiment_type,
                    'confidence': raw_confidence,
                    'model': 'roberta_enhanced',
                    'raw_score': raw_score,
                    'geo_adjusted': geo_adjusted_score,
                    'key_phrases_used': len(key_phrases) > 0
                }
                
                logger.debug(f"üìä Analyse RoBERTa: {raw_score:.3f} -> {smoothed_score:.3f} -> {sentiment_type}")
                return result
                
            except Exception as e:
                logger.error(f"Erreur RoBERTa: {e}")
                # Fallback syst√©matique en cas d'erreur
        
        # FALLBACK : M√©thode traditionnelle am√©lior√©e
        return self._analyze_traditional_enhanced(text)
    
    def _analyze_traditional_enhanced(self, text: str) -> Dict[str, Any]:
        """
        üìö Analyse traditionnelle avec am√©liorations significatives
        """
        try:
            scores = []
            confidences = []
            
            # TextBlob avec pond√©ration
            if TEXTBLOB_AVAILABLE:
                blob = TextBlob(text)
                tb_score = blob.sentiment.polarity
                tb_confidence = blob.sentiment.subjectivity  # Subjectivit√© comme proxy de confiance
                scores.append(tb_score)
                confidences.append(tb_confidence)
            
            # VADER avec analyse d√©taill√©e
            if self.sia:
                vader_scores = self.sia.polarity_scores(text)
                vader_score = vader_scores['compound']
                vader_confidence = 1.0 - abs(vader_scores['neu'] - 0.5)  # Confiance bas√©e sur neutralit√©
                scores.append(vader_score)
                confidences.append(vader_confidence)
            
            # Moyenne pond√©r√©e par confiance
            if scores:
                total_confidence = sum(confidences)
                if total_confidence > 0:
                    raw_score = sum(s * c for s, c in zip(scores, confidences)) / total_confidence
                    avg_confidence = total_confidence / len(confidences)
                else:
                    raw_score = sum(scores) / len(scores)
                    avg_confidence = 0.5
            else:
                raw_score = 0.0
                avg_confidence = 0.0
            
            # üéØ Contexte g√©opolitique
            geo_adjusted = self._apply_geopolitical_context(text, raw_score)
            
            # üìä Lissage
            smoothed = self._smooth_score(geo_adjusted)
            
            # üè∑Ô∏è Cat√©gorisation avec biais positif
            sentiment_type = self._categorize_sentiment(smoothed, avg_confidence)
            
            return {
                'score': smoothed,
                'type': sentiment_type,
                'confidence': avg_confidence,
                'model': 'traditional_enhanced',
                'raw_score': raw_score,
                'geo_adjusted': geo_adjusted
            }
            
        except Exception as e:
            logger.error(f"Erreur analyse traditionnelle: {e}")
            # Fallback ultra simple
            return {
                'score': 0.05,  # L√©ger biais positif
                'type': 'neutral_positive',
                'confidence': 0.1,
                'model': 'error_fallback'
            }
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """M√©thode de compatibilit√©"""
        return self.analyze_sentiment_with_score(text)
    
    def analyze_article(self, title: str, content: str) -> Dict[str, Any]:
        """
        üì∞ Analyse d'article avec pond√©ration optimis√©e
        """
        # Le titre a plus d'importance (70/30) pour la g√©opolitique
        title_analysis = self.analyze_sentiment_with_score(title)
        content_analysis = self.analyze_sentiment_with_score(content[:1500])  # Contenu limit√©
        
        # Score combin√© avec pond√©ration titre renforc√©e
        combined_score = (title_analysis['score'] * 0.7) + (content_analysis['score'] * 0.3)
        combined_confidence = (title_analysis['confidence'] * 0.7) + (content_analysis['confidence'] * 0.3)
        
        # Recat√©gorisation avec v√©rification de coh√©rence
        sentiment_type = self._categorize_sentiment(combined_score, combined_confidence)
        
        # V√©rification de coh√©rence entre titre et contenu
        title_type = title_analysis['type']
        content_type = content_analysis['type']
        
        # Si conflit majeur, favoriser le titre
        if (title_type in ['positive', 'neutral_positive'] and 
            content_type in ['negative', 'neutral_negative']):
            logger.debug(f"‚ö†Ô∏è Conflit d√©tect√©: titre={title_type}, contenu={content_type} -> priorit√© titre")
            # Ajuster l√©g√®rement vers le titre
            combined_score = (combined_score * 0.3) + (title_analysis['score'] * 0.7)
            sentiment_type = self._categorize_sentiment(combined_score, combined_confidence)
        
        return {
            'score': combined_score,
            'type': sentiment_type,
            'confidence': combined_confidence,
            'model': title_analysis['model'],
            'title_score': title_analysis['score'],
            'content_score': content_analysis['score'],
            'title_sentiment': title_type,
            'content_sentiment': content_type
        }
    
    def get_detailed_sentiment_category(self, result: Dict[str, Any]) -> Tuple[str, float]:
        """
        M√©thode utilitaire pour la migration
        """
        return result['type'], result['confidence']
    
    def get_sentiment_explanation(self, result: Dict[str, Any]) -> str:
        """
        üí¨ G√©n√®re une explication textuelle du sentiment
        """
        score = result['score']
        sentiment = result['type']
        confidence = result['confidence']
        
        explanations = {
            'positive': f"Sentiment clairement positif (score: {score:.2f}, confiance: {confidence:.0%})",
            'neutral_positive': f"Tendance positive (score: {score:.2f}, confiance: {confidence:.0%})",
            'neutral_negative': f"Tendance n√©gative (score: {score:.2f}, confiance: {confidence:.0%})",
            'negative': f"Sentiment clairement n√©gatif (score: {score:.2f}, confiance: {confidence:.0%})"
        }
        
        return explanations.get(sentiment, "Sentiment ind√©termin√©")

# Ajout de l'import manquant
import re
