# Flask/geo_entity_integration.py - Int√©gration Geo-Narrative + Entity Extractor

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from collections import defaultdict, Counter

logger = logging.getLogger(__name__)

class GeoEntityIntegration:
    """
    Orchestrateur combinant l'analyse g√©o-narrative avec l'extraction d'entit√©s.
    Permet d'enrichir les patterns transnationaux avec des entit√©s g√©opolitiques.
    """
    
    def __init__(self, geo_narrative_analyzer, entity_extractor, entity_db_manager):
        """
        Initialise l'int√©grateur
        
        Args:
            geo_narrative_analyzer: Instance de GeoNarrativeAnalyzer
            entity_extractor: Instance de GeopoliticalEntityExtractor
            entity_db_manager: Instance de EntityDatabaseManager
        """
        self.geo_analyzer = geo_narrative_analyzer
        self.entity_extractor = entity_extractor
        self.entity_db = entity_db_manager
        
        logger.info("‚úÖ GeoEntityIntegration initialis√©")
    
    # =========================================================================
    # M√âTHODE PRINCIPALE - ANALYSE ENRICHIE
    # =========================================================================
    
    def analyze_patterns_with_entities(self, days: int = 7, min_countries: int = 2) -> List[Dict[str, Any]]:
        """
        Analyse les patterns transnationaux ET extrait les entit√©s associ√©es
        
        Args:
            days: P√©riode d'analyse en jours
            min_countries: Nombre minimum de pays pour consid√©rer un pattern
            
        Returns:
            Liste de patterns enrichis avec entit√©s g√©opolitiques
        """
        try:
            logger.info(f"üîç Analyse enrichie: {days} jours, min {min_countries} pays")
            
            # 1. D√©tecter les patterns transnationaux
            patterns = self.geo_analyzer.detect_transnational_patterns(
                days=days, 
                min_countries=min_countries
            )
            
            if not patterns:
                logger.warning("‚ö†Ô∏è Aucun pattern d√©tect√©")
                return []
            
            logger.info(f"üìä {len(patterns)} patterns d√©tect√©s, enrichissement en cours...")
            
            # 2. Enrichir chaque pattern avec des entit√©s
            enriched_patterns = []
            for pattern in patterns:
                enriched = self._enrich_pattern_with_entities(pattern)
                enriched_patterns.append(enriched)
            
            # 3. Calculer des statistiques globales
            enriched_patterns = self._add_global_statistics(enriched_patterns)
            
            logger.info(f"‚úÖ {len(enriched_patterns)} patterns enrichis")
            
            return enriched_patterns
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse enrichie: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _enrich_pattern_with_entities(self, pattern: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrichit un pattern avec les entit√©s g√©opolitiques extraites
        
        Args:
            pattern: Pattern brut de geo_narrative_analyzer
            
        Returns:
            Pattern enrichi avec entit√©s
        """
        try:
            pattern_text = pattern['pattern']
            
            # Extraire les entit√©s du pattern
            entities = self.entity_extractor.extract_entities(pattern_text)
            
            # Enrichir le pattern
            pattern['entities'] = {
                'locations': entities.get('locations', []),
                'organizations': entities.get('organizations', []),
                'persons': entities.get('persons', []),
                'groups': entities.get('groups', []),
                'events': entities.get('events', [])
            }
            
            # Compter les entit√©s
            pattern['entity_counts'] = {
                'locations': len(entities.get('locations', [])),
                'organizations': len(entities.get('organizations', [])),
                'persons': len(entities.get('persons', [])),
                'groups': len(entities.get('groups', [])),
                'events': len(entities.get('events', []))
            }
            
            # Calculer un score de "richesse" du pattern
            total_entities = sum(pattern['entity_counts'].values())
            pattern['entity_richness_score'] = total_entities
            
            return pattern
            
        except Exception as e:
            logger.error(f"‚ùå Erreur enrichissement pattern: {e}")
            # Retourner le pattern original en cas d'erreur
            pattern['entities'] = {}
            pattern['entity_counts'] = {}
            pattern['entity_richness_score'] = 0
            return pattern
    
    def _add_global_statistics(self, patterns: List[Dict]) -> List[Dict]:
        """
        Ajoute des statistiques globales sur les entit√©s
        
        Args:
            patterns: Liste de patterns enrichis
            
        Returns:
            Patterns avec statistiques ajout√©es
        """
        # Compter toutes les entit√©s
        all_locations = []
        all_organizations = []
        all_persons = []
        
        for pattern in patterns:
            entities = pattern.get('entities', {})
            all_locations.extend([e['text'] for e in entities.get('locations', [])])
            all_organizations.extend([e['text'] for e in entities.get('organizations', [])])
            all_persons.extend([e['text'] for e in entities.get('persons', [])])
        
        # Calculer les entit√©s les plus fr√©quentes
        location_freq = Counter(all_locations)
        org_freq = Counter(all_organizations)
        person_freq = Counter(all_persons)
        
        # Ajouter aux m√©tadonn√©es de chaque pattern
        for pattern in patterns:
            pattern['global_context'] = {
                'top_locations': location_freq.most_common(5),
                'top_organizations': org_freq.most_common(5),
                'top_persons': person_freq.most_common(5)
            }
        
        return patterns
    
    # =========================================================================
    # ANALYSE PAR ARTICLES
    # =========================================================================
    
    def analyze_articles_comprehensive(self, days: int = 7) -> Dict[str, Any]:
        """
        Analyse compl√®te : patterns + entit√©s pour tous les articles
        
        Args:
            days: P√©riode d'analyse
            
        Returns:
            Rapport complet avec patterns et r√©seau d'entit√©s
        """
        try:
            logger.info(f"üîé Analyse compl√®te sur {days} jours...")
            
            # 1. R√©cup√©rer les articles
            articles_by_country = self.geo_analyzer._get_recent_articles_by_country(days)
            
            all_articles = []
            for country, articles in articles_by_country.items():
                all_articles.extend(articles)
            
            logger.info(f"üìö {len(all_articles)} articles √† analyser")
            
            # 2. Analyser les patterns
            patterns = self.analyze_patterns_with_entities(days=days, min_countries=2)
            
            # 3. Cr√©er le r√©seau d'entit√©s global
            entity_network = self.entity_extractor.extract_geopolitical_network(all_articles)
            
            # 4. Sauvegarder les entit√©s en base de donn√©es
            self._save_entities_to_db(all_articles)
            
            # 5. Compiler le rapport
            report = {
                'analysis_date': datetime.now().isoformat(),
                'period_days': days,
                'summary': {
                    'total_articles': len(all_articles),
                    'countries_analyzed': len(articles_by_country),
                    'patterns_detected': len(patterns),
                    'unique_locations': len(entity_network['top_locations']),
                    'unique_organizations': len(entity_network['top_organizations']),
                    'unique_persons': len(entity_network['top_persons'])
                },
                'patterns': patterns,
                'entity_network': entity_network,
                'articles_by_country': {
                    country: len(articles) 
                    for country, articles in articles_by_country.items()
                }
            }
            
            logger.info("‚úÖ Analyse compl√®te termin√©e")
            
            return report
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse compl√®te: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    def _save_entities_to_db(self, articles: List[Dict]) -> None:
        """
        Sauvegarde les entit√©s extraites en base de donn√©es
        
        Args:
            articles: Liste d'articles √† traiter
        """
        try:
            saved_count = 0
            
            for article in articles:
                # Extraire les entit√©s
                analysis = self.entity_extractor.analyze_article(article)
                entities = analysis['entities']
                
                # Sauvegarder pour chaque cat√©gorie
                article_id = article.get('id')
                if not article_id:
                    continue
                
                # Locations
                for entity in entities.get('locations', []):
                    self.entity_db.save_entity(
                        article_id=article_id,
                        entity_text=entity['text'],
                        entity_type='location',
                        entity_label=entity.get('label', 'GPE'),
                        context=entity.get('context', '')
                    )
                
                # Organizations
                for entity in entities.get('organizations', []):
                    self.entity_db.save_entity(
                        article_id=article_id,
                        entity_text=entity['text'],
                        entity_type='organization',
                        entity_label=entity.get('label', 'ORG'),
                        context=entity.get('context', '')
                    )
                
                # Persons
                for entity in entities.get('persons', []):
                    self.entity_db.save_entity(
                        article_id=article_id,
                        entity_text=entity['text'],
                        entity_type='person',
                        entity_label=entity.get('label', 'PERSON'),
                        context=entity.get('context', '')
                    )
                
                saved_count += 1
            
            logger.info(f"üíæ Entit√©s sauvegard√©es pour {saved_count} articles")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde entit√©s: {e}")
    
    # =========================================================================
    # RECHERCHE ET FILTRAGE
    # =========================================================================
    
    def find_patterns_by_entity(
        self, 
        entity_name: str, 
        entity_type: Optional[str] = None,
        days: int = 7
    ) -> List[Dict[str, Any]]:
        """
        Trouve tous les patterns mentionnant une entit√© sp√©cifique
        
        Args:
            entity_name: Nom de l'entit√© (ex: "France", "ONU", "Macron")
            entity_type: Type d'entit√© (optionnel: location, organization, person)
            days: P√©riode d'analyse
            
        Returns:
            Liste de patterns contenant cette entit√©
        """
        try:
            # Analyser avec entit√©s
            patterns = self.analyze_patterns_with_entities(days=days)
            
            # Filtrer les patterns contenant l'entit√©
            matching_patterns = []
            
            for pattern in patterns:
                entities = pattern.get('entities', {})
                
                # Chercher dans toutes les cat√©gories ou une cat√©gorie sp√©cifique
                categories = [entity_type] if entity_type else entities.keys()
                
                for category in categories:
                    entity_list = entities.get(category, [])
                    for entity in entity_list:
                        if entity_name.lower() in entity['text'].lower():
                            matching_patterns.append(pattern)
                            break
            
            logger.info(f"üîç {len(matching_patterns)} patterns trouv√©s pour '{entity_name}'")
            
            return matching_patterns
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche par entit√©: {e}")
            return []
    
    def get_entity_timeline(
        self, 
        entity_name: str, 
        days: int = 30
    ) -> Dict[str, Any]:
        """
        Chronologie d'apparition d'une entit√© dans les patterns
        
        Args:
            entity_name: Nom de l'entit√©
            days: P√©riode d'analyse
            
        Returns:
            Timeline avec patterns et dates
        """
        try:
            # R√©cup√©rer les entit√©s de la BDD
            entities = self.entity_db.get_entities_by_text(entity_name)
            
            # Grouper par date
            timeline = defaultdict(list)
            
            for entity in entities:
                date = entity.get('created_at', '').split('T')[0]  # Extraire juste la date
                timeline[date].append({
                    'article_id': entity.get('article_id'),
                    'context': entity.get('context', '')[:100] + '...',
                    'type': entity.get('entity_type')
                })
            
            # Convertir en liste tri√©e
            sorted_timeline = [
                {
                    'date': date,
                    'occurrences': len(items),
                    'examples': items[:3]  # Limiter √† 3 exemples par jour
                }
                for date, items in sorted(timeline.items())
            ]
            
            return {
                'entity': entity_name,
                'total_occurrences': sum(len(items) for items in timeline.values()),
                'days_analyzed': days,
                'timeline': sorted_timeline
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur timeline entit√©: {e}")
            return {}
    
    # =========================================================================
    # VISUALISATION DES RELATIONS
    # =========================================================================
    
    def get_entity_relations(
        self, 
        days: int = 7
    ) -> Dict[str, Any]:
        """
        Extrait les relations entre entit√©s (co-occurrences)
        
        Args:
            days: P√©riode d'analyse
            
        Returns:
            Graphe de relations entre entit√©s
        """
        try:
            # Analyser les articles
            articles_by_country = self.geo_analyzer._get_recent_articles_by_country(days)
            all_articles = []
            for articles in articles_by_country.values():
                all_articles.extend(articles)
            
            # Cr√©er le graphe de relations
            relations = []
            
            for article in all_articles:
                # Extraire les entit√©s de l'article
                analysis = self.entity_extractor.analyze_article(article)
                entities = analysis['entities']
                
                # Cr√©er des relations entre locations et organizations
                locations = [e['text'] for e in entities.get('locations', [])]
                organizations = [e['text'] for e in entities.get('organizations', [])]
                persons = [e['text'] for e in entities.get('persons', [])]
                
                # Relations location-organization
                for loc in locations:
                    for org in organizations:
                        relations.append({
                            'source': loc,
                            'target': org,
                            'type': 'location-organization',
                            'article_id': article.get('id')
                        })
                
                # Relations organization-person
                for org in organizations:
                    for person in persons:
                        relations.append({
                            'source': org,
                            'target': person,
                            'type': 'organization-person',
                            'article_id': article.get('id')
                        })
            
            # Compter les relations
            relation_counts = Counter(
                (r['source'], r['target'], r['type']) 
                for r in relations
            )
            
            # Formater pour visualisation (format D3.js/vis.js)
            nodes = set()
            for relation in relations:
                nodes.add(relation['source'])
                nodes.add(relation['target'])
            
            graph = {
                'nodes': [{'id': node, 'label': node} for node in nodes],
                'edges': [
                    {
                        'source': source,
                        'target': target,
                        'weight': count,
                        'type': rel_type
                    }
                    for (source, target, rel_type), count in relation_counts.most_common(50)
                ],
                'metadata': {
                    'total_nodes': len(nodes),
                    'total_edges': len(relation_counts),
                    'analysis_date': datetime.now().isoformat(),
                    'period_days': days
                }
            }
            
            return graph
            
        except Exception as e:
            logger.error(f"‚ùå Erreur relations entit√©s: {e}")
            import traceback
            traceback.print_exc()
            return {}
    
    # =========================================================================
    # EXPORT ET RAPPORTS
    # =========================================================================
    
    def generate_comprehensive_report(
        self, 
        days: int = 7,
        format: str = 'json'
    ) -> str:
        """
        G√©n√®re un rapport complet combinant patterns et entit√©s
        
        Args:
            days: P√©riode d'analyse
            format: Format de sortie ('json' ou 'markdown')
            
        Returns:
            Rapport format√©
        """
        try:
            # Analyse compl√®te
            analysis = self.analyze_articles_comprehensive(days=days)
            
            if format == 'json':
                import json
                return json.dumps(analysis, ensure_ascii=False, indent=2)
            
            elif format == 'markdown':
                # G√©n√©rer un rapport Markdown
                md = f"# üåç Rapport G√©opolitique\n\n"
                md += f"**Date:** {analysis['analysis_date']}\n"
                md += f"**P√©riode:** {days} jours\n\n"
                
                md += "## üìä R√©sum√©\n\n"
                summary = analysis['summary']
                md += f"- Articles analys√©s: **{summary['total_articles']}**\n"
                md += f"- Pays: **{summary['countries_analyzed']}**\n"
                md += f"- Patterns d√©tect√©s: **{summary['patterns_detected']}**\n"
                md += f"- Lieux uniques: **{summary['unique_locations']}**\n"
                md += f"- Organisations uniques: **{summary['unique_organizations']}**\n"
                md += f"- Personnalit√©s uniques: **{summary['unique_persons']}**\n\n"
                
                md += "## üîç Top Patterns Transnationaux\n\n"
                for i, pattern in enumerate(analysis['patterns'][:10], 1):
                    md += f"### {i}. \"{pattern['pattern']}\"\n\n"
                    md += f"- Pays: {', '.join(pattern['countries'])}\n"
                    md += f"- Occurrences: {pattern.get('total_occurrences', 0)}\n"
                    
                    # Entit√©s associ√©es
                    entities = pattern.get('entities', {})
                    if entities.get('locations'):
                        locs = [e['text'] for e in entities['locations'][:3]]
                        md += f"- Lieux: {', '.join(locs)}\n"
                    if entities.get('organizations'):
                        orgs = [e['text'] for e in entities['organizations'][:3]]
                        md += f"- Organisations: {', '.join(orgs)}\n"
                    
                    md += "\n"
                
                return md
            
            else:
                return "Format non support√©"
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration rapport: {e}")
            return f"Erreur: {str(e)}"
