# Flask/geopolitical_entity_extractor.py - Extraction d'entit√©s g√©opolitiques
import spacy
import logging
from typing import List, Dict, Any, Set
from collections import Counter
from datetime import datetime
import json

logger = logging.getLogger(__name__)

class GeopoliticalEntityExtractor:
    """
    Extracteur d'entit√©s g√©opolitiques utilisant SpaCy
    Identifie : pays, villes, organisations, personnalit√©s, √©v√©nements
    """
    
    # Cat√©gories d'entit√©s g√©opolitiques
    ENTITY_CATEGORIES = {
        'GPE': 'location',      # Pays, villes, √©tats
        'LOC': 'location',      # Lieux g√©ographiques
        'ORG': 'organization',  # Organisations, gouvernements
        'PERSON': 'person',     # Personnalit√©s
        'EVENT': 'event',       # √âv√©nements
        'NORP': 'group'         # Nationalit√©s, groupes religieux/politiques
    }
    
    # Liste √©tendue de pays et r√©gions (pour enrichissement)
    KNOWN_COUNTRIES = {
        'france', '√©tats-unis', 'usa', 'chine', 'russie', 'inde', 'japon',
        'allemagne', 'royaume-uni', 'italie', 'espagne', 'canada', 'mexique',
        'br√©sil', 'argentine', 'australie', 'cor√©e du sud', 'iran', 'irak',
        'syrie', 'isra√´l', 'palestine', '√©gypte', 'arabie saoudite', 'turquie',
        'ukraine', 'pologne', 'su√®de', 'norv√®ge', 'finlande', 'belgique',
        'pays-bas', 'suisse', 'autriche', 'portugal', 'gr√®ce', 'hongrie'
    }
    
    # Organisations internationales importantes
    KNOWN_ORGANIZATIONS = {
        'onu', 'otan', 'union europ√©enne', 'ue', 'omc', 'fmi', 'banque mondiale',
        'oms', 'unesco', 'opep', 'g7', 'g20', 'brics', 'asean', 'osce',
        'conseil de s√©curit√©', 'parlement europ√©en', 'commission europ√©enne'
    }
    
    def __init__(self, model_name: str = "fr_core_news_lg"):
        """
        Initialise l'extracteur avec le mod√®le SpaCy fran√ßais
        
        Args:
            model_name: Nom du mod√®le SpaCy √† utiliser
        """
        self.model_name = model_name
        self.nlp = None
        self._load_model()
    
    def _load_model(self):
        """Charge le mod√®le SpaCy"""
        try:
            self.nlp = spacy.load(self.model_name)
            logger.info(f"‚úÖ Mod√®le SpaCy '{self.model_name}' charg√© avec succ√®s")
        except OSError:
            logger.error(f"‚ùå Mod√®le '{self.model_name}' non trouv√©")
            logger.info("üì• Installation du mod√®le...")
            try:
                import subprocess
                subprocess.run(
                    ["python", "-m", "spacy", "download", self.model_name],
                    check=True
                )
                self.nlp = spacy.load(self.model_name)
                logger.info(f"‚úÖ Mod√®le '{self.model_name}' install√© et charg√©")
            except Exception as e:
                logger.error(f"‚ùå Impossible d'installer le mod√®le: {e}")
                raise
    
    def extract_entities(self, text: str) -> Dict[str, Any]:
        """
        Extrait toutes les entit√©s g√©opolitiques d'un texte
        
        Args:
            text: Texte √† analyser
            
        Returns:
            Dictionnaire contenant les entit√©s par cat√©gorie
        """
        if not text or not self.nlp:
            return self._empty_result()
        
        try:
            doc = self.nlp(text)
            
            entities = {
                'locations': [],
                'organizations': [],
                'persons': [],
                'events': [],
                'groups': [],
                'all_entities': []
            }
            
            seen_entities = set()
            
            for ent in doc.ents:
                entity_text = ent.text.strip()
                entity_lower = entity_text.lower()
                
                # √âviter les doublons
                if entity_lower in seen_entities:
                    continue
                seen_entities.add(entity_lower)
                
                entity_data = {
                    'text': entity_text,
                    'label': ent.label_,
                    'start': ent.start_char,
                    'end': ent.end_char
                }
                
                # Cat√©goriser selon le type SpaCy
                category = self.ENTITY_CATEGORIES.get(ent.label_, 'other')
                
                if category == 'location':
                    entities['locations'].append(entity_data)
                elif category == 'organization':
                    entities['organizations'].append(entity_data)
                elif category == 'person':
                    entities['persons'].append(entity_data)
                elif category == 'event':
                    entities['events'].append(entity_data)
                elif category == 'group':
                    entities['groups'].append(entity_data)
                
                entities['all_entities'].append(entity_data)
            
            # Enrichir avec d√©tection personnalis√©e
            self._enrich_with_known_entities(text, entities)
            
            return entities
            
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction entit√©s: {e}")
            return self._empty_result()
    
    def _enrich_with_known_entities(self, text: str, entities: Dict[str, Any]):
        """
        Enrichit la d√©tection avec des listes pr√©d√©finies
        """
        text_lower = text.lower()
        
        # D√©tecter pays connus
        for country in self.KNOWN_COUNTRIES:
            if country in text_lower:
                # V√©rifier si d√©j√† d√©tect√©
                if not any(e['text'].lower() == country for e in entities['locations']):
                    entities['locations'].append({
                        'text': country.title(),
                        'label': 'GPE',
                        'start': -1,
                        'end': -1,
                        'source': 'enrichment'
                    })
        
        # D√©tecter organisations connues
        for org in self.KNOWN_ORGANIZATIONS:
            if org in text_lower:
                if not any(e['text'].lower() == org for e in entities['organizations']):
                    entities['organizations'].append({
                        'text': org.upper() if len(org) <= 4 else org.title(),
                        'label': 'ORG',
                        'start': -1,
                        'end': -1,
                        'source': 'enrichment'
                    })
    
    def _empty_result(self) -> Dict[str, Any]:
        """Retourne un r√©sultat vide"""
        return {
            'locations': [],
            'organizations': [],
            'persons': [],
            'events': [],
            'groups': [],
            'all_entities': []
        }
    
    def extract_with_context(self, text: str, context_window: int = 50) -> Dict[str, Any]:
        """
        Extrait les entit√©s avec leur contexte
        
        Args:
            text: Texte √† analyser
            context_window: Nombre de caract√®res de contexte autour de l'entit√©
            
        Returns:
            Entit√©s avec contexte
        """
        entities = self.extract_entities(text)
        
        # Ajouter le contexte pour chaque entit√©
        for category in ['locations', 'organizations', 'persons', 'events', 'groups']:
            for entity in entities[category]:
                if entity.get('start', -1) >= 0:
                    start = max(0, entity['start'] - context_window)
                    end = min(len(text), entity['end'] + context_window)
                    entity['context'] = text[start:end]
        
        return entities
    
    def get_most_frequent_entities(self, text: str, top_n: int = 10) -> Dict[str, List[tuple]]:
        """
        Retourne les entit√©s les plus fr√©quentes par cat√©gorie
        
        Args:
            text: Texte √† analyser
            top_n: Nombre d'entit√©s √† retourner par cat√©gorie
            
        Returns:
            Dictionnaire des entit√©s les plus fr√©quentes avec leur compte
        """
        entities = self.extract_entities(text)
        
        result = {}
        
        for category in ['locations', 'organizations', 'persons', 'groups']:
            entity_texts = [e['text'] for e in entities[category]]
            counter = Counter(entity_texts)
            result[category] = counter.most_common(top_n)
        
        return result
    
    def analyze_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyse un article complet et extrait toutes les informations
        
        Args:
            article: Dictionnaire contenant 'title' et 'content'
            
        Returns:
            Analyse compl√®te avec entit√©s et statistiques
        """
        title = article.get('title', '')
        content = article.get('content', '')
        full_text = f"{title}. {content}"
        
        # Extraction des entit√©s
        entities = self.extract_entities(full_text)
        
        # Statistiques
        stats = {
            'total_entities': len(entities['all_entities']),
            'locations_count': len(entities['locations']),
            'organizations_count': len(entities['organizations']),
            'persons_count': len(entities['persons']),
            'events_count': len(entities['events']),
            'groups_count': len(entities['groups'])
        }
        
        # Entit√©s les plus fr√©quentes
        frequent = self.get_most_frequent_entities(full_text, top_n=5)
        
        return {
            'entities': entities,
            'statistics': stats,
            'frequent_entities': frequent,
            'analyzed_at': datetime.now().isoformat()
        }
    
    def extract_geopolitical_network(self, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyse un ensemble d'articles pour cr√©er un r√©seau d'entit√©s g√©opolitiques
        
        Args:
            articles: Liste d'articles √† analyser
            
        Returns:
            R√©seau d'entit√©s avec relations et statistiques globales
        """
        all_locations = []
        all_organizations = []
        all_persons = []
        location_org_pairs = []
        
        for article in articles:
            analysis = self.analyze_article(article)
            entities = analysis['entities']
            
            # Collecter toutes les entit√©s
            all_locations.extend([e['text'] for e in entities['locations']])
            all_organizations.extend([e['text'] for e in entities['organizations']])
            all_persons.extend([e['text'] for e in entities['persons']])
            
            # Cr√©er des paires location-organisation (co-occurrence)
            for loc in entities['locations']:
                for org in entities['organizations']:
                    location_org_pairs.append((loc['text'], org['text']))
        
        # Calculer les fr√©quences
        location_freq = Counter(all_locations)
        org_freq = Counter(all_organizations)
        person_freq = Counter(all_persons)
        pair_freq = Counter(location_org_pairs)
        
        return {
            'top_locations': location_freq.most_common(20),
            'top_organizations': org_freq.most_common(20),
            'top_persons': person_freq.most_common(20),
            'top_relations': pair_freq.most_common(20),
            'total_articles_analyzed': len(articles),
            'network_density': len(pair_freq) / max(len(location_freq) * len(org_freq), 1)
        }
    
    def format_for_display(self, entities: Dict[str, Any]) -> str:
        """
        Formate les entit√©s pour affichage lisible
        
        Args:
            entities: R√©sultat de extract_entities()
            
        Returns:
            Cha√Æne format√©e
        """
        output = []
        
        if entities['locations']:
            output.append("üåç LIEUX:")
            for e in entities['locations'][:10]:
                output.append(f"  ‚Ä¢ {e['text']}")
        
        if entities['organizations']:
            output.append("\nüèõÔ∏è ORGANISATIONS:")
            for e in entities['organizations'][:10]:
                output.append(f"  ‚Ä¢ {e['text']}")
        
        if entities['persons']:
            output.append("\nüë§ PERSONNALIT√âS:")
            for e in entities['persons'][:10]:
                output.append(f"  ‚Ä¢ {e['text']}")
        
        if entities['groups']:
            output.append("\nüë• GROUPES:")
            for e in entities['groups'][:10]:
                output.append(f"  ‚Ä¢ {e['text']}")
        
        return "\n".join(output) if output else "Aucune entit√© d√©tect√©e"
    
    def export_to_json(self, entities: Dict[str, Any], filepath: str):
        """
        Exporte les entit√©s en JSON
        
        Args:
            entities: R√©sultat de extract_entities()
            filepath: Chemin du fichier de sortie
        """
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(entities, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ Entit√©s export√©es vers {filepath}")
        except Exception as e:
            logger.error(f"‚ùå Erreur export JSON: {e}")